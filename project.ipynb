{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8420aa2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4738979",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Quora_QP_Train.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da2cad16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404285</th>\n",
       "      <td>404285</td>\n",
       "      <td>433578</td>\n",
       "      <td>379845</td>\n",
       "      <td>How many keywords are there in the Racket prog...</td>\n",
       "      <td>How many keywords are there in PERL Programmin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404286</th>\n",
       "      <td>404286</td>\n",
       "      <td>18840</td>\n",
       "      <td>155606</td>\n",
       "      <td>Do you believe there is life after death?</td>\n",
       "      <td>Is it true that there is life after death?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404287</th>\n",
       "      <td>404287</td>\n",
       "      <td>537928</td>\n",
       "      <td>537929</td>\n",
       "      <td>What is one coin?</td>\n",
       "      <td>What's this coin?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404288</th>\n",
       "      <td>404288</td>\n",
       "      <td>537930</td>\n",
       "      <td>537931</td>\n",
       "      <td>What is the approx annual cost of living while...</td>\n",
       "      <td>I am having little hairfall problem but I want...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404289</th>\n",
       "      <td>404289</td>\n",
       "      <td>537932</td>\n",
       "      <td>537933</td>\n",
       "      <td>What is like to have sex with cousin?</td>\n",
       "      <td>What is it like to have sex with your cousin?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>404290 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id    qid1    qid2  \\\n",
       "0            0       1       2   \n",
       "1            1       3       4   \n",
       "2            2       5       6   \n",
       "3            3       7       8   \n",
       "4            4       9      10   \n",
       "...        ...     ...     ...   \n",
       "404285  404285  433578  379845   \n",
       "404286  404286   18840  155606   \n",
       "404287  404287  537928  537929   \n",
       "404288  404288  537930  537931   \n",
       "404289  404289  537932  537933   \n",
       "\n",
       "                                                question1  \\\n",
       "0       What is the step by step guide to invest in sh...   \n",
       "1       What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "2       How can I increase the speed of my internet co...   \n",
       "3       Why am I mentally very lonely? How can I solve...   \n",
       "4       Which one dissolve in water quikly sugar, salt...   \n",
       "...                                                   ...   \n",
       "404285  How many keywords are there in the Racket prog...   \n",
       "404286          Do you believe there is life after death?   \n",
       "404287                                  What is one coin?   \n",
       "404288  What is the approx annual cost of living while...   \n",
       "404289              What is like to have sex with cousin?   \n",
       "\n",
       "                                                question2  is_duplicate  \n",
       "0       What is the step by step guide to invest in sh...             0  \n",
       "1       What would happen if the Indian government sto...             0  \n",
       "2       How can Internet speed be increased by hacking...             0  \n",
       "3       Find the remainder when [math]23^{24}[/math] i...             0  \n",
       "4                 Which fish would survive in salt water?             0  \n",
       "...                                                   ...           ...  \n",
       "404285  How many keywords are there in PERL Programmin...             0  \n",
       "404286         Is it true that there is life after death?             1  \n",
       "404287                                  What's this coin?             0  \n",
       "404288  I am having little hairfall problem but I want...             0  \n",
       "404289      What is it like to have sex with your cousin?             0  \n",
       "\n",
       "[404290 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2bb16c",
   "metadata": {},
   "source": [
    "## Doing preprocessing on the dataset of quora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff2356fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(q):\n",
    "    \n",
    "    q = str(q).lower().strip()\n",
    "    \n",
    "    # Replace certain special characters with their string equivalents\n",
    "    q = q.replace('%', ' percent')\n",
    "    q = q.replace('$', ' dollar ')\n",
    "    q = q.replace('₹', ' rupee ')\n",
    "    q = q.replace('€', ' euro ')\n",
    "    q = q.replace('@', ' at ')\n",
    "    \n",
    "    # The pattern '[math]' appears around 900 times in the whole dataset.\n",
    "    q = q.replace('[math]', '')\n",
    "    \n",
    "    # Replacing some numbers with string equivalents (not perfect, can be done better to account for more cases)\n",
    "    q = q.replace(',000,000,000 ', 'b ')\n",
    "    q = q.replace(',000,000 ', 'm ')\n",
    "    q = q.replace(',000 ', 'k ')\n",
    "    q = re.sub(r'([0-9]+)000000000', r'\\1b', q)\n",
    "    q = re.sub(r'([0-9]+)000000', r'\\1m', q)\n",
    "    q = re.sub(r'([0-9]+)000', r'\\1k', q)\n",
    "    \n",
    "    # Decontracting words\n",
    "    # https://en.wikipedia.org/wiki/Wikipedia%3aList_of_English_contractions\n",
    "    # https://stackoverflow.com/a/19794953\n",
    "    contractions = { \n",
    "    \"ain't\": \"am not\",\n",
    "    \"aren't\": \"are not\",\n",
    "    \"can't\": \"can not\",\n",
    "    \"can't've\": \"can not have\",\n",
    "    \"'cause\": \"because\",\n",
    "    \"could've\": \"could have\",\n",
    "    \"couldn't\": \"could not\",\n",
    "    \"couldn't've\": \"could not have\",\n",
    "    \"didn't\": \"did not\",\n",
    "    \"doesn't\": \"does not\",\n",
    "    \"don't\": \"do not\",\n",
    "    \"hadn't\": \"had not\",\n",
    "    \"hadn't've\": \"had not have\",\n",
    "    \"hasn't\": \"has not\",\n",
    "    \"haven't\": \"have not\",\n",
    "    \"he'd\": \"he would\",\n",
    "    \"he'd've\": \"he would have\",\n",
    "    \"he'll\": \"he will\",\n",
    "    \"he'll've\": \"he will have\",\n",
    "    \"he's\": \"he is\",\n",
    "    \"how'd\": \"how did\",\n",
    "    \"how'd'y\": \"how do you\",\n",
    "    \"how'll\": \"how will\",\n",
    "    \"how's\": \"how is\",\n",
    "    \"i'd\": \"i would\",\n",
    "    \"i'd've\": \"i would have\",\n",
    "    \"i'll\": \"i will\",\n",
    "    \"i'll've\": \"i will have\",\n",
    "    \"i'm\": \"i am\",\n",
    "    \"i've\": \"i have\",\n",
    "    \"isn't\": \"is not\",\n",
    "    \"it'd\": \"it would\",\n",
    "    \"it'd've\": \"it would have\",\n",
    "    \"it'll\": \"it will\",\n",
    "    \"it'll've\": \"it will have\",\n",
    "    \"it's\": \"it is\",\n",
    "    \"let's\": \"let us\",\n",
    "    \"ma'am\": \"madam\",\n",
    "    \"mayn't\": \"may not\",\n",
    "    \"might've\": \"might have\",\n",
    "    \"mightn't\": \"might not\",\n",
    "    \"mightn't've\": \"might not have\",\n",
    "    \"must've\": \"must have\",\n",
    "    \"mustn't\": \"must not\",\n",
    "    \"mustn't've\": \"must not have\",\n",
    "    \"needn't\": \"need not\",\n",
    "    \"needn't've\": \"need not have\",\n",
    "    \"o'clock\": \"of the clock\",\n",
    "    \"oughtn't\": \"ought not\",\n",
    "    \"oughtn't've\": \"ought not have\",\n",
    "    \"shan't\": \"shall not\",\n",
    "    \"sha'n't\": \"shall not\",\n",
    "    \"shan't've\": \"shall not have\",\n",
    "    \"she'd\": \"she would\",\n",
    "    \"she'd've\": \"she would have\",\n",
    "    \"she'll\": \"she will\",\n",
    "    \"she'll've\": \"she will have\",\n",
    "    \"she's\": \"she is\",\n",
    "    \"should've\": \"should have\",\n",
    "    \"shouldn't\": \"should not\",\n",
    "    \"shouldn't've\": \"should not have\",\n",
    "    \"so've\": \"so have\",\n",
    "    \"so's\": \"so as\",\n",
    "    \"that'd\": \"that would\",\n",
    "    \"that'd've\": \"that would have\",\n",
    "    \"that's\": \"that is\",\n",
    "    \"there'd\": \"there would\",\n",
    "    \"there'd've\": \"there would have\",\n",
    "    \"there's\": \"there is\",\n",
    "    \"they'd\": \"they would\",\n",
    "    \"they'd've\": \"they would have\",\n",
    "    \"they'll\": \"they will\",\n",
    "    \"they'll've\": \"they will have\",\n",
    "    \"they're\": \"they are\",\n",
    "    \"they've\": \"they have\",\n",
    "    \"to've\": \"to have\",\n",
    "    \"wasn't\": \"was not\",\n",
    "    \"we'd\": \"we would\",\n",
    "    \"we'd've\": \"we would have\",\n",
    "    \"we'll\": \"we will\",\n",
    "    \"we'll've\": \"we will have\",\n",
    "    \"we're\": \"we are\",\n",
    "    \"we've\": \"we have\",\n",
    "    \"weren't\": \"were not\",\n",
    "    \"what'll\": \"what will\",\n",
    "    \"what'll've\": \"what will have\",\n",
    "    \"what're\": \"what are\",\n",
    "    \"what's\": \"what is\",\n",
    "    \"what've\": \"what have\",\n",
    "    \"when's\": \"when is\",\n",
    "    \"when've\": \"when have\",\n",
    "    \"where'd\": \"where did\",\n",
    "    \"where's\": \"where is\",\n",
    "    \"where've\": \"where have\",\n",
    "    \"who'll\": \"who will\",\n",
    "    \"who'll've\": \"who will have\",\n",
    "    \"who's\": \"who is\",\n",
    "    \"who've\": \"who have\",\n",
    "    \"why's\": \"why is\",\n",
    "    \"why've\": \"why have\",\n",
    "    \"will've\": \"will have\",\n",
    "    \"won't\": \"will not\",\n",
    "    \"won't've\": \"will not have\",\n",
    "    \"would've\": \"would have\",\n",
    "    \"wouldn't\": \"would not\",\n",
    "    \"wouldn't've\": \"would not have\",\n",
    "    \"y'all\": \"you all\",\n",
    "    \"y'all'd\": \"you all would\",\n",
    "    \"y'all'd've\": \"you all would have\",\n",
    "    \"y'all're\": \"you all are\",\n",
    "    \"y'all've\": \"you all have\",\n",
    "    \"you'd\": \"you would\",\n",
    "    \"you'd've\": \"you would have\",\n",
    "    \"you'll\": \"you will\",\n",
    "    \"you'll've\": \"you will have\",\n",
    "    \"you're\": \"you are\",\n",
    "    \"you've\": \"you have\"\n",
    "    }\n",
    "\n",
    "    q_decontracted = []\n",
    "\n",
    "    for word in q.split():\n",
    "        if word in contractions:\n",
    "            word = contractions[word]\n",
    "\n",
    "        q_decontracted.append(word)\n",
    "\n",
    "    q = ' '.join(q_decontracted)\n",
    "    q = q.replace(\"'ve\", \" have\")\n",
    "    q = q.replace(\"n't\", \" not\")\n",
    "    q = q.replace(\"'re\", \" are\")\n",
    "    q = q.replace(\"'ll\", \" will\")\n",
    "    \n",
    "    # Removing HTML tags\n",
    "    q = BeautifulSoup(q)\n",
    "    q = q.get_text()\n",
    "    \n",
    "    # Remove punctuations\n",
    "    pattern = re.compile('\\W')\n",
    "    q = re.sub(pattern, ' ', q).strip()\n",
    "\n",
    "    \n",
    "    return q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb1f3d4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i have already  was not done'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess(\"I've already! wasn't <b>done</b>?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe659745",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['question1'] = df['question1'].apply(preprocess)\n",
    "df['question2'] = df['question2'].apply(preprocess)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54fb63e3",
   "metadata": {},
   "source": [
    "## Basic Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ef970b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## feature to get the length of question\n",
    "df['q1_len'] = df['question1'].str.len() \n",
    "df['q2_len'] = df['question2'].str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f64c74cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## feature getting the number of words from each question\n",
    "df['q1_num_words'] = df['question1'].apply(lambda row: len(row.split(\" \")))\n",
    "df['q2_num_words'] = df['question2'].apply(lambda row: len(row.split(\" \")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4552b252",
   "metadata": {},
   "outputs": [],
   "source": [
    "## function to get the number of common words that are unique in both q1 and q2\n",
    "def common_words(row):\n",
    "    w1 = set(map(lambda word: word.lower().strip(), row['question1'].split(\" \")))\n",
    "    w2 = set(map(lambda word: word.lower().strip(), row['question2'].split(\" \")))    \n",
    "    return len(w1 & w2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "30869c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## applying above function\n",
    "df['word_common'] = df.apply(common_words, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cadbd12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## function to get the total no. of unique words combine from q1 and q2\n",
    "def total_words(row):\n",
    "    w1 = set(map(lambda word: word.lower().strip(), row['question1'].split(\" \")))\n",
    "    w2 = set(map(lambda word: word.lower().strip(), row['question2'].split(\" \")))    \n",
    "    return (len(w1) + len(w2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6e6eb3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## applying above function \n",
    "df['word_total'] = df.apply(total_words, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "41c6e61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['word_share'] = round(df['word_common']/df['word_total'],2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c51b24",
   "metadata": {},
   "source": [
    "## Performing advance feature engineering( token, length-based,fuzzy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "436605dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "def fetch_token_features(row):\n",
    "    \n",
    "    q1 = row['question1']\n",
    "    q2 = row['question2']\n",
    "    \n",
    "    SAFE_DIV = 0.0001 \n",
    "\n",
    "    STOP_WORDS = stopwords.words(\"english\")\n",
    "    \n",
    "    token_features = [0.0]*8\n",
    "    \n",
    "    # Converting the Sentence into Tokens: \n",
    "    q1_tokens = q1.split()\n",
    "    q2_tokens = q2.split()\n",
    "    \n",
    "    if len(q1_tokens) == 0 or len(q2_tokens) == 0:\n",
    "        return token_features\n",
    "\n",
    "    # Get the non-stopwords in Questions\n",
    "    q1_words = set([word for word in q1_tokens if word not in STOP_WORDS])\n",
    "    q2_words = set([word for word in q2_tokens if word not in STOP_WORDS])\n",
    "    \n",
    "    #Get the stopwords in Questions\n",
    "    q1_stops = set([word for word in q1_tokens if word in STOP_WORDS])\n",
    "    q2_stops = set([word for word in q2_tokens if word in STOP_WORDS])\n",
    "    \n",
    "    # Get the common non-stopwords from Question pair\n",
    "    common_word_count = len(q1_words.intersection(q2_words))\n",
    "    \n",
    "    # Get the common stopwords from Question pair\n",
    "    common_stop_count = len(q1_stops.intersection(q2_stops))\n",
    "    \n",
    "    # Get the common Tokens from Question pair\n",
    "    common_token_count = len(set(q1_tokens).intersection(set(q2_tokens)))\n",
    "    \n",
    "    \n",
    "    token_features[0] = common_word_count / (min(len(q1_words), len(q2_words)) + SAFE_DIV)\n",
    "    token_features[1] = common_word_count / (max(len(q1_words), len(q2_words)) + SAFE_DIV)\n",
    "    token_features[2] = common_stop_count / (min(len(q1_stops), len(q2_stops)) + SAFE_DIV)\n",
    "    token_features[3] = common_stop_count / (max(len(q1_stops), len(q2_stops)) + SAFE_DIV)\n",
    "    token_features[4] = common_token_count / (min(len(q1_tokens), len(q2_tokens)) + SAFE_DIV)\n",
    "    token_features[5] = common_token_count / (max(len(q1_tokens), len(q2_tokens)) + SAFE_DIV)\n",
    "    \n",
    "    # Last word of both question is same or not\n",
    "    token_features[6] = int(q1_tokens[-1] == q2_tokens[-1])\n",
    "    \n",
    "    # First word of both question is same or not\n",
    "    token_features[7] = int(q1_tokens[0] == q2_tokens[0])\n",
    "    \n",
    "    return token_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0d58bd8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Applying the above function\n",
    "token_features = df.apply(fetch_token_features, axis=1)\n",
    "\n",
    "df[\"cwc_min\"]       = list(map(lambda x: x[0], token_features))\n",
    "df[\"cwc_max\"]       = list(map(lambda x: x[1], token_features))\n",
    "df[\"csc_min\"]       = list(map(lambda x: x[2], token_features))\n",
    "df[\"csc_max\"]       = list(map(lambda x: x[3], token_features))\n",
    "df[\"ctc_min\"]       = list(map(lambda x: x[4], token_features))\n",
    "df[\"ctc_max\"]       = list(map(lambda x: x[5], token_features))\n",
    "df[\"last_word_eq\"]  = list(map(lambda x: x[6], token_features))\n",
    "df[\"first_word_eq\"] = list(map(lambda x: x[7], token_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "881219da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rapidfuzz import fuzz\n",
    "\n",
    "def fetch_fuzzy_features(row):\n",
    "    q1 = str(row['question1'])\n",
    "    q2 = str(row['question2'])\n",
    "\n",
    "    return [\n",
    "        fuzz.QRatio(q1, q2),\n",
    "        fuzz.partial_ratio(q1, q2),\n",
    "        fuzz.token_sort_ratio(q1, q2),\n",
    "        fuzz.token_set_ratio(q1, q2)\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "18a11a29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 404290/404290 [00:46<00:00, 8635.32it/s] \n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "fuzzy_scores = df.progress_apply(fetch_fuzzy_features, axis=1, result_type='expand')\n",
    "fuzzy_scores.columns = ['fuzz_ratio', 'fuzz_partial_ratio', 'token_sort_ratio', 'token_set_ratio']\n",
    "\n",
    "df = pd.concat([df, fuzzy_scores], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3d426027",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>q1_len</th>\n",
       "      <th>q2_len</th>\n",
       "      <th>q1_num_words</th>\n",
       "      <th>q2_num_words</th>\n",
       "      <th>...</th>\n",
       "      <th>csc_min</th>\n",
       "      <th>csc_max</th>\n",
       "      <th>ctc_min</th>\n",
       "      <th>ctc_max</th>\n",
       "      <th>last_word_eq</th>\n",
       "      <th>first_word_eq</th>\n",
       "      <th>fuzz_ratio</th>\n",
       "      <th>fuzz_partial_ratio</th>\n",
       "      <th>token_sort_ratio</th>\n",
       "      <th>token_set_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>what is the step by step guide to invest in sh...</td>\n",
       "      <td>what is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "      <td>56</td>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>0.916659</td>\n",
       "      <td>0.785709</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>92.561983</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>92.561983</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>what is the story of kohinoor  koh i noor  dia...</td>\n",
       "      <td>what would happen if the indian government sto...</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>87</td>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>0.749981</td>\n",
       "      <td>0.599988</td>\n",
       "      <td>0.699993</td>\n",
       "      <td>0.466664</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>65.693431</td>\n",
       "      <td>77.083333</td>\n",
       "      <td>63.157895</td>\n",
       "      <td>85.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>how can i increase the speed of my internet co...</td>\n",
       "      <td>how can internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>58</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.399992</td>\n",
       "      <td>0.249997</td>\n",
       "      <td>0.399996</td>\n",
       "      <td>0.285712</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>53.846154</td>\n",
       "      <td>56.565657</td>\n",
       "      <td>66.153846</td>\n",
       "      <td>66.153846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>why am i mentally very lonely  how can i solve it</td>\n",
       "      <td>find the remainder when 23  24   math  is divi...</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>58</td>\n",
       "      <td>12</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.514019</td>\n",
       "      <td>38.775510</td>\n",
       "      <td>37.254902</td>\n",
       "      <td>36.170213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>which one dissolve in water quikly sugar  salt...</td>\n",
       "      <td>which fish would survive in salt water</td>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "      <td>38</td>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999950</td>\n",
       "      <td>0.666644</td>\n",
       "      <td>0.571420</td>\n",
       "      <td>0.307690</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>46.017699</td>\n",
       "      <td>64.615385</td>\n",
       "      <td>46.846847</td>\n",
       "      <td>66.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2                                          question1  \\\n",
       "0   0     1     2  what is the step by step guide to invest in sh...   \n",
       "1   1     3     4  what is the story of kohinoor  koh i noor  dia...   \n",
       "2   2     5     6  how can i increase the speed of my internet co...   \n",
       "3   3     7     8  why am i mentally very lonely  how can i solve it   \n",
       "4   4     9    10  which one dissolve in water quikly sugar  salt...   \n",
       "\n",
       "                                           question2  is_duplicate  q1_len  \\\n",
       "0  what is the step by step guide to invest in sh...             0      65   \n",
       "1  what would happen if the indian government sto...             0      50   \n",
       "2  how can internet speed be increased by hacking...             0      72   \n",
       "3  find the remainder when 23  24   math  is divi...             0      49   \n",
       "4             which fish would survive in salt water             0      75   \n",
       "\n",
       "   q2_len  q1_num_words  q2_num_words  ...   csc_min   csc_max   ctc_min  \\\n",
       "0      56            14            12  ...  0.999983  0.999983  0.916659   \n",
       "1      87            12            17  ...  0.749981  0.599988  0.699993   \n",
       "2      58            14            10  ...  0.399992  0.249997  0.399996   \n",
       "3      58            12            16  ...  0.000000  0.000000  0.000000   \n",
       "4      38            15             7  ...  0.999950  0.666644  0.571420   \n",
       "\n",
       "    ctc_max  last_word_eq  first_word_eq  fuzz_ratio  fuzz_partial_ratio  \\\n",
       "0  0.785709           0.0            1.0   92.561983          100.000000   \n",
       "1  0.466664           0.0            1.0   65.693431           77.083333   \n",
       "2  0.285712           0.0            1.0   53.846154           56.565657   \n",
       "3  0.000000           0.0            0.0   35.514019           38.775510   \n",
       "4  0.307690           0.0            1.0   46.017699           64.615385   \n",
       "\n",
       "   token_sort_ratio  token_set_ratio  \n",
       "0         92.561983       100.000000  \n",
       "1         63.157895        85.714286  \n",
       "2         66.153846        66.153846  \n",
       "3         37.254902        36.170213  \n",
       "4         46.846847        66.666667  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "646109c7",
   "metadata": {},
   "source": [
    "## Performing basic EDA on the data to get the insights about new feature and their mutual relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "69e8f374",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>what is the step by step guide to invest in sh...</td>\n",
       "      <td>what is the step by step guide to invest in sh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>what is the story of kohinoor  koh i noor  dia...</td>\n",
       "      <td>what would happen if the indian government sto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>how can i increase the speed of my internet co...</td>\n",
       "      <td>how can internet speed be increased by hacking...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>why am i mentally very lonely  how can i solve it</td>\n",
       "      <td>find the remainder when 23  24   math  is divi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>which one dissolve in water quikly sugar  salt...</td>\n",
       "      <td>which fish would survive in salt water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404285</th>\n",
       "      <td>how many keywords are there in the racket prog...</td>\n",
       "      <td>how many keywords are there in perl programmin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404286</th>\n",
       "      <td>do you believe there is life after death</td>\n",
       "      <td>is it true that there is life after death</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404287</th>\n",
       "      <td>what is one coin</td>\n",
       "      <td>what is this coin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404288</th>\n",
       "      <td>what is the approx annual cost of living while...</td>\n",
       "      <td>i am having little hairfall problem but i want...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404289</th>\n",
       "      <td>what is like to have sex with cousin</td>\n",
       "      <td>what is it like to have sex with your cousin</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>404290 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                question1  \\\n",
       "0       what is the step by step guide to invest in sh...   \n",
       "1       what is the story of kohinoor  koh i noor  dia...   \n",
       "2       how can i increase the speed of my internet co...   \n",
       "3       why am i mentally very lonely  how can i solve it   \n",
       "4       which one dissolve in water quikly sugar  salt...   \n",
       "...                                                   ...   \n",
       "404285  how many keywords are there in the racket prog...   \n",
       "404286           do you believe there is life after death   \n",
       "404287                                   what is one coin   \n",
       "404288  what is the approx annual cost of living while...   \n",
       "404289               what is like to have sex with cousin   \n",
       "\n",
       "                                                question2  \n",
       "0       what is the step by step guide to invest in sh...  \n",
       "1       what would happen if the indian government sto...  \n",
       "2       how can internet speed be increased by hacking...  \n",
       "3       find the remainder when 23  24   math  is divi...  \n",
       "4                  which fish would survive in salt water  \n",
       "...                                                   ...  \n",
       "404285  how many keywords are there in perl programmin...  \n",
       "404286          is it true that there is life after death  \n",
       "404287                                  what is this coin  \n",
       "404288  i am having little hairfall problem but i want...  \n",
       "404289       what is it like to have sex with your cousin  \n",
       "\n",
       "[404290 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## making seperate df for questions\n",
    "ques_df = df[['question1','question2']]\n",
    "ques_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "83565b6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(404290, 20)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>q1_len</th>\n",
       "      <th>q2_len</th>\n",
       "      <th>q1_num_words</th>\n",
       "      <th>q2_num_words</th>\n",
       "      <th>word_common</th>\n",
       "      <th>word_total</th>\n",
       "      <th>word_share</th>\n",
       "      <th>cwc_min</th>\n",
       "      <th>cwc_max</th>\n",
       "      <th>csc_min</th>\n",
       "      <th>csc_max</th>\n",
       "      <th>ctc_min</th>\n",
       "      <th>ctc_max</th>\n",
       "      <th>last_word_eq</th>\n",
       "      <th>first_word_eq</th>\n",
       "      <th>fuzz_ratio</th>\n",
       "      <th>fuzz_partial_ratio</th>\n",
       "      <th>token_sort_ratio</th>\n",
       "      <th>token_set_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "      <td>56</td>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>23</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.999980</td>\n",
       "      <td>0.833319</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>0.916659</td>\n",
       "      <td>0.785709</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>92.561983</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>92.561983</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>87</td>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "      <td>8</td>\n",
       "      <td>26</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.799984</td>\n",
       "      <td>0.399996</td>\n",
       "      <td>0.749981</td>\n",
       "      <td>0.599988</td>\n",
       "      <td>0.699993</td>\n",
       "      <td>0.466664</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>65.693431</td>\n",
       "      <td>77.083333</td>\n",
       "      <td>63.157895</td>\n",
       "      <td>85.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>58</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.399992</td>\n",
       "      <td>0.333328</td>\n",
       "      <td>0.399992</td>\n",
       "      <td>0.249997</td>\n",
       "      <td>0.399996</td>\n",
       "      <td>0.285712</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>53.846154</td>\n",
       "      <td>56.565657</td>\n",
       "      <td>66.153846</td>\n",
       "      <td>66.153846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>58</td>\n",
       "      <td>12</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.514019</td>\n",
       "      <td>38.775510</td>\n",
       "      <td>37.254902</td>\n",
       "      <td>36.170213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "      <td>38</td>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.399992</td>\n",
       "      <td>0.199998</td>\n",
       "      <td>0.999950</td>\n",
       "      <td>0.666644</td>\n",
       "      <td>0.571420</td>\n",
       "      <td>0.307690</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>46.017699</td>\n",
       "      <td>64.615385</td>\n",
       "      <td>46.846847</td>\n",
       "      <td>66.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   is_duplicate  q1_len  q2_len  q1_num_words  q2_num_words  word_common  \\\n",
       "0             0      65      56            14            12           11   \n",
       "1             0      50      87            12            17            8   \n",
       "2             0      72      58            14            10            4   \n",
       "3             0      49      58            12            16            1   \n",
       "4             0      75      38            15             7            4   \n",
       "\n",
       "   word_total  word_share   cwc_min   cwc_max   csc_min   csc_max   ctc_min  \\\n",
       "0          23        0.48  0.999980  0.833319  0.999983  0.999983  0.916659   \n",
       "1          26        0.31  0.799984  0.399996  0.749981  0.599988  0.699993   \n",
       "2          24        0.17  0.399992  0.333328  0.399992  0.249997  0.399996   \n",
       "3          22        0.05  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "4          21        0.19  0.399992  0.199998  0.999950  0.666644  0.571420   \n",
       "\n",
       "    ctc_max  last_word_eq  first_word_eq  fuzz_ratio  fuzz_partial_ratio  \\\n",
       "0  0.785709           0.0            1.0   92.561983          100.000000   \n",
       "1  0.466664           0.0            1.0   65.693431           77.083333   \n",
       "2  0.285712           0.0            1.0   53.846154           56.565657   \n",
       "3  0.000000           0.0            0.0   35.514019           38.775510   \n",
       "4  0.307690           0.0            1.0   46.017699           64.615385   \n",
       "\n",
       "   token_sort_ratio  token_set_ratio  \n",
       "0         92.561983       100.000000  \n",
       "1         63.157895        85.714286  \n",
       "2         66.153846        66.153846  \n",
       "3         37.254902        36.170213  \n",
       "4         46.846847        66.666667  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## droping irrelevant columns from the df\n",
    "final_df = df.drop(columns=['id','qid1','qid2','question1','question2'])\n",
    "print(final_df.shape)\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d8a1a849",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "# Reset + clean\n",
    "ques_df = ques_df.dropna(subset=['question1', 'question2']).reset_index(drop=True)\n",
    "\n",
    "# Combine question1 and question2\n",
    "questions = list(ques_df['question1']) + list(ques_df['question2'])\n",
    "\n",
    "# Fit vectorizer\n",
    "cv = CountVectorizer(max_features=3000)\n",
    "X = cv.fit_transform(questions)  # sparse (800,000, 3000)\n",
    "\n",
    "# Split back\n",
    "half = X.shape[0] // 2\n",
    "q1_sparse = X[:half]\n",
    "q2_sparse = X[half:]\n",
    "\n",
    "# Combine sparse horizontally\n",
    "bow_sparse = hstack([q1_sparse, q2_sparse])  # (N, 6000)\n",
    "\n",
    "# Convert sparse to DataFrame safely (in chunks if needed)\n",
    "bow_df = pd.DataFrame.sparse.from_spmatrix(bow_sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "89385df8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>5990</th>\n",
       "      <th>5991</th>\n",
       "      <th>5992</th>\n",
       "      <th>5993</th>\n",
       "      <th>5994</th>\n",
       "      <th>5995</th>\n",
       "      <th>5996</th>\n",
       "      <th>5997</th>\n",
       "      <th>5998</th>\n",
       "      <th>5999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404285</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404286</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404287</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404288</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404289</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>404290 rows × 6000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0     1     2     3     4     5     6     7     8     9     ...  5990  \\\n",
       "0          0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "1          0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "2          0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "3          0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "4          0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "...      ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   ...   \n",
       "404285     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "404286     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "404287     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "404288     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "404289     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "\n",
       "        5991  5992  5993  5994  5995  5996  5997  5998  5999  \n",
       "0          0     0     0     0     0     0     0     0     0  \n",
       "1          0     0     0     0     0     0     0     0     0  \n",
       "2          0     0     0     0     0     0     0     0     0  \n",
       "3          0     0     0     0     0     0     0     0     0  \n",
       "4          0     0     0     0     0     0     0     0     0  \n",
       "...      ...   ...   ...   ...   ...   ...   ...   ...   ...  \n",
       "404285     0     0     0     0     0     0     0     0     0  \n",
       "404286     0     0     0     0     0     0     0     0     0  \n",
       "404287     0     0     0     0     0     0     0     0     0  \n",
       "404288     0     0     0     0     0     0     0     0     0  \n",
       "404289     0     0     0     1     0     0     0     0     0  \n",
       "\n",
       "[404290 rows x 6000 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7e4d51f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## creating final_df from existing df an dbowdf on which we can apply our model\n",
    "final_df = pd.concat([final_df.reset_index(drop=True), bow_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "95fecb08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 404290 entries, 0 to 404289\n",
      "Columns: 6020 entries, is_duplicate to 5999\n",
      "dtypes: Sparse[int64, 0](6000), float64(13), int64(7)\n",
      "memory usage: 143.5 MB\n"
     ]
    }
   ],
   "source": [
    "final_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "044beaf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## splitting into train_test\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "# 1. Separate target\n",
    "y = final_df.iloc[:, 0].values  # target (first column)\n",
    "# 2. Separate other features (if any, excluding the target column and BoW)\n",
    "# If you had features like fuzzy scores, extract them here\n",
    "dense_features = final_df.iloc[:, 1:19].values  # assuming 22 non-BoW features\n",
    "# 3. Combine dense and sparse features\n",
    "X = hstack([csr_matrix(dense_features), bow_sparse])  # shape: (n, 6023)\n",
    "# 4. Split without converting to dense\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cd46a7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## training model and making prediction\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred = lr.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "edcc8175",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "89dc2178",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7271513022830147"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b2bc3d4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\tanmai\\anaconda3\\lib\\site-packages (3.0.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\tanmai\\appdata\\roaming\\python\\python312\\site-packages (from xgboost) (1.26.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\tanmai\\appdata\\roaming\\python\\python312\\site-packages (from xgboost) (1.15.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~atplotlib (c:\\Users\\tanmai\\anaconda3\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~atplotlib (c:\\Users\\tanmai\\anaconda3\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~atplotlib (c:\\Users\\tanmai\\anaconda3\\Lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ddaf791e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8054737935640258"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## trying xgboostclassifier \n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb = XGBClassifier(tree_method='hist', use_label_encoder=False, eval_metric='logloss')\n",
    "xgb.fit(X_train, y_train)\n",
    "y_pred = xgb.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca7b76e",
   "metadata": {},
   "source": [
    "## The accuracy(80.547%) is good so far, Now doing hyperparameter tunning in order to get much better prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c39a538d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "Best Parameters (Randomized): {'subsample': 0.6, 'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.2, 'gamma': 1, 'colsample_bytree': 1.0}\n",
      "Accuracy: 0.8150832323332261\n",
      "Log Loss: 0.37921089166331484\n"
     ]
    }
   ],
   "source": [
    "## randomized tunning\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "import numpy as np\n",
    "\n",
    "# Base model\n",
    "xgb = XGBClassifier(\n",
    "    tree_method='hist',\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='logloss',\n",
    "    verbosity=0\n",
    ")\n",
    "\n",
    "# Parameter distributions to sample from\n",
    "param_dist = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 5, 7, 10],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "    'gamma': [0, 1, 5]\n",
    "}\n",
    "\n",
    "# Randomized Search\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=xgb,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=20,                 # Number of combinations to try\n",
    "    scoring='neg_log_loss',   # Use 'accuracy' if you prefer\n",
    "    cv=3,\n",
    "    verbose=1,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Fit\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Best model\n",
    "best_xgb = random_search.best_estimator_\n",
    "\n",
    "# Evaluation\n",
    "y_pred = best_xgb.predict(X_test)\n",
    "y_proba = best_xgb.predict_proba(X_test)\n",
    "\n",
    "print(\"Best Parameters (Randomized):\", random_search.best_params_)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Log Loss:\", log_loss(y_test, y_proba))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "34d00672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Accuracy: 0.8150832323332261\n",
      "Final Log Loss: 0.37921089166331484\n"
     ]
    }
   ],
   "source": [
    "## Re-Trinimg the model based on parameter afetr hyper parameter tunning\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "\n",
    "# Use best params from RandomizedSearchCV\n",
    "xgb_final = XGBClassifier(\n",
    "    tree_method='hist',\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='logloss',\n",
    "    subsample=0.6,\n",
    "    n_estimators=300,\n",
    "    max_depth=5,\n",
    "    learning_rate=0.2,\n",
    "    gamma=1,\n",
    "    colsample_bytree=1.0\n",
    ")\n",
    "\n",
    "# Fit on full training data\n",
    "xgb_final.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = xgb_final.predict(X_test)\n",
    "y_proba = xgb_final.predict_proba(X_test)\n",
    "\n",
    "# Evaluation\n",
    "print(\"Final Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Final Log Loss:\", log_loss(y_test, y_proba))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f134b36",
   "metadata": {},
   "source": [
    "## so far we are done with making model now checking its prediction on new set of question but before that we have to make the input of (1,6019) dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3dd0038d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_common_words(q1,q2):\n",
    "    w1 = set(map(lambda word: word.lower().strip(), q1.split(\" \")))\n",
    "    w2 = set(map(lambda word: word.lower().strip(), q2.split(\" \")))    \n",
    "    return len(w1 & w2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "54d6484e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_total_words(q1,q2):\n",
    "    w1 = set(map(lambda word: word.lower().strip(), q1.split(\" \")))\n",
    "    w2 = set(map(lambda word: word.lower().strip(), q2.split(\" \")))    \n",
    "    return (len(w1) + len(w2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "8b4d215c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_fetch_token_features(q1,q2):\n",
    "    \n",
    "    SAFE_DIV = 0.0001 \n",
    "\n",
    "    STOP_WORDS = stopwords.words(\"english\")\n",
    "    \n",
    "    token_features = [0.0]*8\n",
    "    \n",
    "    # Converting the Sentence into Tokens: \n",
    "    q1_tokens = q1.split()\n",
    "    q2_tokens = q2.split()\n",
    "    \n",
    "    if len(q1_tokens) == 0 or len(q2_tokens) == 0:\n",
    "        return token_features\n",
    "\n",
    "    # Get the non-stopwords in Questions\n",
    "    q1_words = set([word for word in q1_tokens if word not in STOP_WORDS])\n",
    "    q2_words = set([word for word in q2_tokens if word not in STOP_WORDS])\n",
    "    \n",
    "    #Get the stopwords in Questions\n",
    "    q1_stops = set([word for word in q1_tokens if word in STOP_WORDS])\n",
    "    q2_stops = set([word for word in q2_tokens if word in STOP_WORDS])\n",
    "    \n",
    "    # Get the common non-stopwords from Question pair\n",
    "    common_word_count = len(q1_words.intersection(q2_words))\n",
    "    \n",
    "    # Get the common stopwords from Question pair\n",
    "    common_stop_count = len(q1_stops.intersection(q2_stops))\n",
    "    \n",
    "    # Get the common Tokens from Question pair\n",
    "    common_token_count = len(set(q1_tokens).intersection(set(q2_tokens)))\n",
    "    \n",
    "    \n",
    "    token_features[0] = common_word_count / (min(len(q1_words), len(q2_words)) + SAFE_DIV)\n",
    "    token_features[1] = common_word_count / (max(len(q1_words), len(q2_words)) + SAFE_DIV)\n",
    "    token_features[2] = common_stop_count / (min(len(q1_stops), len(q2_stops)) + SAFE_DIV)\n",
    "    token_features[3] = common_stop_count / (max(len(q1_stops), len(q2_stops)) + SAFE_DIV)\n",
    "    token_features[4] = common_token_count / (min(len(q1_tokens), len(q2_tokens)) + SAFE_DIV)\n",
    "    token_features[5] = common_token_count / (max(len(q1_tokens), len(q2_tokens)) + SAFE_DIV)\n",
    "    \n",
    "    # Last word of both question is same or not\n",
    "    token_features[6] = int(q1_tokens[-1] == q2_tokens[-1])\n",
    "    \n",
    "    # First word of both question is same or not\n",
    "    token_features[7] = int(q1_tokens[0] == q2_tokens[0])\n",
    "    \n",
    "    return token_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "23821ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_fetch_fuzzy_features(q1, q2):\n",
    "    return [\n",
    "        fuzz.QRatio(q1, q2),\n",
    "        fuzz.partial_ratio(q1, q2),\n",
    "        fuzz.token_sort_ratio(q1, q2)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "b7173ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import hstack, csr_matrix\n",
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "def query_point_creator(q1, q2):\n",
    "    input_query = []\n",
    "\n",
    "    # Preprocess\n",
    "    q1 = preprocess(q1)\n",
    "    q2 = preprocess(q2)\n",
    "\n",
    "    # Basic handcrafted features (7)\n",
    "    input_query.append(len(q1))                        # q1_len\n",
    "    input_query.append(len(q2))                        # q2_len\n",
    "    input_query.append(len(q1.split()))                # q1_num_words\n",
    "    input_query.append(len(q2.split()))                # q2_num_words\n",
    "    wc = test_common_words(q1, q2)\n",
    "    wt = test_total_words(q1, q2)\n",
    "    input_query.append(wc)                             # word_common\n",
    "    input_query.append(wt)                             # word_total\n",
    "    input_query.append(round(wc / wt, 2) if wt else 0) # word_share\n",
    "\n",
    "    # Token-based features (8)\n",
    "    token_features = test_fetch_token_features(q1, q2)  # returns 8\n",
    "    assert len(token_features) == 8\n",
    "    input_query.extend(token_features)\n",
    "\n",
    "    # Fuzzy features (3)\n",
    "    fuzzy_features = [\n",
    "        fuzz.QRatio(q1, q2),\n",
    "        fuzz.partial_ratio(q1, q2),\n",
    "        fuzz.token_sort_ratio(q1, q2)\n",
    "    ]\n",
    "    input_query.extend(fuzzy_features)\n",
    "\n",
    "    # ✅ Final handcrafted features count must be 18\n",
    "    assert len(input_query) == 18, f\"Got {len(input_query)} features instead of 18\"\n",
    "\n",
    "    # Bag of Words\n",
    "    q1_bow = cv.transform([q1])\n",
    "    q2_bow = cv.transform([q2])\n",
    "\n",
    "    return hstack([\n",
    "        csr_matrix(np.array(input_query).reshape(1, -1)),  # (1, 18)\n",
    "        q1_bow,                                            # (1, 3000)\n",
    "        q2_bow                                             # (1, 3000)\n",
    "    ])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "3d7e8033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['q1_len', 'q2_len', 'q1_num_words', 'q2_num_words', 'word_common',\n",
      "       'word_total', 'word_share', 'cwc_min', 'cwc_max', 'csc_min', 'csc_max',\n",
      "       'ctc_min', 'ctc_max', 'last_word_eq', 'first_word_eq', 'fuzz_ratio',\n",
      "       'fuzz_partial_ratio', 'token_sort_ratio'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(final_df.columns[1:19])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "04f5aa9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 6018)\n"
     ]
    }
   ],
   "source": [
    "query_vector = query_point_creator(\"How do I learn Python?\", \"What is the best way to learn Python?\")\n",
    "print(query_vector.shape)  # Should be (1, 6018)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "ac6bcf49",
   "metadata": {},
   "outputs": [],
   "source": [
    "q1 = 'What is the capital of India?'\n",
    "q2 = 'What is the current capital of Pakistan?'\n",
    "q3 = 'Where is the capital of india?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "e3ec8f46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_final.predict(query_point_creator(q1,q3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "b857ff18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle.dump(xgb_final,open('model.pkl','wb'))\n",
    "pickle.dump(cv,open('cv.pkl','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8959b6a",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
